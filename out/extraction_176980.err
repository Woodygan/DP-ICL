Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  25%|██▌       | 1/4 [01:28<04:25, 88.41s/it]Downloading shards:  50%|█████     | 2/4 [03:08<03:10, 95.34s/it]Downloading shards:  75%|███████▌  | 3/4 [04:59<01:42, 102.22s/it]Downloading shards: 100%|██████████| 4/4 [05:48<00:00, 81.26s/it] Downloading shards: 100%|██████████| 4/4 [05:48<00:00, 87.04s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [02:45<08:16, 165.54s/it]Loading checkpoint shards:  50%|█████     | 2/4 [06:44<06:57, 208.58s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [10:07<03:26, 206.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [10:27<00:00, 132.63s/it]Loading checkpoint shards: 100%|██████████| 4/4 [10:27<00:00, 156.85s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
/home/woodygan/.conda/envs/dpicl/lib/python3.8/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
